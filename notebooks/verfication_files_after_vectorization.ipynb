{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12e9728-d3c7-4966-ac15-80acfcfcbdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " VÉRIFICATION: gnn_pytorch_data.pkl\n",
      "============================================================\n",
      " Fichier trouvé\n",
      " Fichier chargeable\n",
      "   Type racine: <class 'dict'>\n",
      " Structure dict avec clés: ['x', 'edge_index', 'edge_attr', 'num_nodes', 'num_edges']\n",
      " Recherche des tenseurs PyTorch...\n",
      "   x: torch.Size([145341, 64]) (torch.float32)\n",
      "   edge_index: torch.Size([2, 678839]) (torch.int64)\n",
      "   edge_attr: torch.Size([678839, 64]) (torch.float32)\n",
      "\n",
      " VALIDATION GNN:\n",
      "   ✅ Nœuds > 0\n",
      "   ✅ Arêtes > 0\n",
      "   ✅ Indices arêtes >= 0\n",
      "   ✅ Indices arêtes < num_nodes\n",
      "   ✅ edge_index shape [2, *]\n",
      "   ✅ Pas NaN dans x\n",
      "   ✅ Pas NaN dans edge_attr\n",
      "   ✅ edge_attr nœuds = edge_index arêtes\n",
      "   ✅ x et edge_attr même feature_dim\n",
      "\n",
      " STATISTIQUES:\n",
      "   Nœuds: 145,341\n",
      "   Arêtes: 678,839\n",
      "   Feature dimension: 64\n",
      "   Degré moyen: 9.34\n",
      "   Device: cpu\n",
      "   Sparsité x: 0.915\n",
      "   Sparsité edge_attr: 0.887\n",
      "\n",
      " CONCLUSION:\n",
      "    PRÊT POUR GNN !\n",
      "\n",
      " VÉRIFICATION: baseline_gnn_pytorch_data.pkl\n",
      "============================================================\n",
      " Fichier trouvé\n",
      " Fichier chargeable\n",
      "   Type racine: <class 'dict'>\n",
      " Structure dict avec clés: ['x', 'edge_index', 'edge_attr', 'num_nodes', 'num_edges']\n",
      " Recherche des tenseurs PyTorch...\n",
      "   x: torch.Size([145341, 64]) (torch.float32)\n",
      "   edge_index: torch.Size([2, 678839]) (torch.int64)\n",
      "   edge_attr: torch.Size([678839, 64]) (torch.float32)\n",
      "\n",
      " VALIDATION GNN:\n",
      "   ✅ Nœuds > 0\n",
      "   ✅ Arêtes > 0\n",
      "   ✅ Indices arêtes >= 0\n",
      "   ✅ Indices arêtes < num_nodes\n",
      "   ✅ edge_index shape [2, *]\n",
      "   ✅ Pas NaN dans x\n",
      "   ✅ Pas NaN dans edge_attr\n",
      "   ✅ edge_attr nœuds = edge_index arêtes\n",
      "   ✅ x et edge_attr même feature_dim\n",
      "\n",
      " STATISTIQUES:\n",
      "   Nœuds: 145,341\n",
      "   Arêtes: 678,839\n",
      "   Feature dimension: 64\n",
      "   Degré moyen: 9.34\n",
      "   Device: cpu\n",
      "   Sparsité x: 0.591\n",
      "   Sparsité edge_attr: 0.944\n",
      "\n",
      " CONCLUSION:\n",
      "    PRÊT POUR GNN !\n",
      "\n",
      "================================================================================\n",
      " RÉSUMÉ FINAL - VERSION CORRIGÉE\n",
      "================================================================================\n",
      " gnn_pytorch_data.pkl: PRÊT POUR GNN\n",
      " baseline_gnn_pytorch_data.pkl: PRÊT POUR GNN\n",
      "\n",
      " BILAN:\n",
      "   Fichiers prêts GNN: 2/2\n",
      "    TOUS LES FICHIERS SONT PRÊTS POUR L'ENTRAÎNEMENT GNN !\n",
      "\n",
      " PROCHAINE ÉTAPE:\n",
      "   Vous pouvez maintenant entraîner votre GNN avec ces données !\n",
      "   Format d'utilisation:\n",
      "   ```python\n",
      "   import pickle\n",
      "   with open('data/05_model_input/gnn_pytorch_data.pkl', 'rb') as f:\n",
      "       data = pickle.load(f)\n",
      "   x, edge_index, edge_attr = data['x'], data['edge_index'], data['edge_attr']\n",
      "   ```\n",
      "\n",
      " TEST DIRECT: gnn_pytorch_data.pkl\n",
      "----------------------------------------\n",
      " Chargement réussi\n",
      "   x (node features): torch.Size([145341, 64]) torch.float32\n",
      "   edge_index (connections): torch.Size([2, 678839]) torch.int64\n",
      "   edge_attr (edge features): torch.Size([678839, 64]) torch.float32\n",
      "\n",
      " Test opération GNN basique:\n",
      "    Moyenne node features: torch.Size([64])\n",
      "    Indexing source/target: torch.Size([678839, 64]), torch.Size([678839, 64])\n",
      "    Message passing basique: torch.Size([678839, 64])\n",
      "    gnn_pytorch_data.pkl est COMPATIBLE avec les opérations GNN !\n",
      "\n",
      " TEST DIRECT: baseline_gnn_pytorch_data.pkl\n",
      "----------------------------------------\n",
      " Chargement réussi\n",
      "   x (node features): torch.Size([145341, 64]) torch.float32\n",
      "   edge_index (connections): torch.Size([2, 678839]) torch.int64\n",
      "   edge_attr (edge features): torch.Size([678839, 64]) torch.float32\n",
      "\n",
      " Test opération GNN basique:\n",
      "    Moyenne node features: torch.Size([64])\n",
      "    Indexing source/target: torch.Size([678839, 64]), torch.Size([678839, 64])\n",
      "    Message passing basique: torch.Size([678839, 64])\n",
      "    baseline_gnn_pytorch_data.pkl est COMPATIBLE avec les opérations GNN !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "def verify_pytorch_object_corrected(file_path):\n",
    "    \"\"\"\n",
    "    Vérifie si un fichier .pkl contient un objet PyTorch valide pour GNN\n",
    "    VERSION CORRIGÉE pour la vraie structure de votre convertisseur\n",
    "    \n",
    "    Returns:\n",
    "        dict: Rapport de vérification complet\n",
    "    \"\"\"\n",
    "    file_name = Path(file_path).name\n",
    "    print(f\"\\n VÉRIFICATION: {file_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    report = {\n",
    "        'file_name': file_name,\n",
    "        'file_exists': False,\n",
    "        'loadable': False,\n",
    "        'contains_pytorch': False,\n",
    "        'gnn_ready': False,\n",
    "        'details': {},\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    # 1. Vérifier existence du fichier\n",
    "    if not Path(file_path).exists():\n",
    "        print(\" Fichier introuvable\")\n",
    "        report['errors'].append(\"Fichier introuvable\")\n",
    "        return report\n",
    "    \n",
    "    report['file_exists'] = True\n",
    "    print(\" Fichier trouvé\")\n",
    "    \n",
    "    # 2. Tenter de charger le fichier\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        report['loadable'] = True\n",
    "        print(\" Fichier chargeable\")\n",
    "        print(f\"   Type racine: {type(data)}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur chargement: {e}\")\n",
    "        report['errors'].append(f\"Erreur chargement: {e}\")\n",
    "        return report\n",
    "    \n",
    "    # 3. Analyser la structure (VERSION CORRIGÉE)\n",
    "    if isinstance(data, dict):\n",
    "        print(f\" Structure dict avec clés: {list(data.keys())}\")\n",
    "        report['details']['structure'] = 'dict'\n",
    "        report['details']['keys'] = list(data.keys())\n",
    "        \n",
    "        # CORRECTION: Vérifier les tenseurs directement au niveau racine\n",
    "        required_tensors = ['x', 'edge_index', 'edge_attr']\n",
    "        tensors_found = {}\n",
    "        \n",
    "        print(\" Recherche des tenseurs PyTorch...\")\n",
    "        \n",
    "        for tensor_name in required_tensors:\n",
    "            if tensor_name in data:\n",
    "                tensor = data[tensor_name]\n",
    "                if torch.is_tensor(tensor):\n",
    "                    print(f\"   {tensor_name}: {tensor.shape} ({tensor.dtype})\")\n",
    "                    tensors_found[tensor_name] = {\n",
    "                        'shape': list(tensor.shape),\n",
    "                        'dtype': str(tensor.dtype),\n",
    "                        'device': str(tensor.device),\n",
    "                        'requires_grad': tensor.requires_grad\n",
    "                    }\n",
    "                    report['contains_pytorch'] = True\n",
    "                else:\n",
    "                    print(f\"    {tensor_name}: pas un tensor ({type(tensor)})\")\n",
    "                    report['errors'].append(f\"{tensor_name} n'est pas un tensor\")\n",
    "            else:\n",
    "                print(f\"    {tensor_name}: manquant\")\n",
    "                report['errors'].append(f\"{tensor_name} manquant\")\n",
    "        \n",
    "        report['details']['tensors'] = tensors_found\n",
    "        \n",
    "        # 4. Validation GNN\n",
    "        if len(tensors_found) == 3:\n",
    "            print(\"\\n VALIDATION GNN:\")\n",
    "            \n",
    "            x = data['x']\n",
    "            edge_index = data['edge_index']\n",
    "            edge_attr = data['edge_attr']\n",
    "            \n",
    "            validation_checks = []\n",
    "            \n",
    "            # Check 1: Dimensions cohérentes\n",
    "            num_nodes = x.size(0)\n",
    "            num_edges = edge_index.size(1)\n",
    "            \n",
    "            validation_checks.append(('Nœuds > 0', num_nodes > 0))\n",
    "            validation_checks.append(('Arêtes > 0', num_edges > 0))\n",
    "            \n",
    "            # Check 2: edge_index valide\n",
    "            max_edge_idx = torch.max(edge_index).item()\n",
    "            min_edge_idx = torch.min(edge_index).item()\n",
    "            \n",
    "            validation_checks.append(('Indices arêtes >= 0', min_edge_idx >= 0))\n",
    "            validation_checks.append(('Indices arêtes < num_nodes', max_edge_idx < num_nodes))\n",
    "            \n",
    "            # Check 3: edge_index shape\n",
    "            validation_checks.append(('edge_index shape [2, *]', edge_index.size(0) == 2))\n",
    "            \n",
    "            # Check 4: Pas de NaN\n",
    "            validation_checks.append(('Pas NaN dans x', not torch.isnan(x).any()))\n",
    "            validation_checks.append(('Pas NaN dans edge_attr', not torch.isnan(edge_attr).any()))\n",
    "            \n",
    "            # Check 5: Dimensions features\n",
    "            validation_checks.append(('edge_attr nœuds = edge_index arêtes', edge_attr.size(0) == num_edges))\n",
    "            \n",
    "            # Check 6: Cohérence dimensions features\n",
    "            validation_checks.append(('x et edge_attr même feature_dim', x.size(1) == edge_attr.size(1)))\n",
    "            \n",
    "            # Afficher résultats\n",
    "            all_passed = True\n",
    "            for check_name, passed in validation_checks:\n",
    "                status = \"✅\" if passed else \"❌\"\n",
    "                print(f\"   {status} {check_name}\")\n",
    "                if not passed:\n",
    "                    all_passed = False\n",
    "                    report['errors'].append(f\"Validation échouée: {check_name}\")\n",
    "            \n",
    "            report['gnn_ready'] = all_passed\n",
    "            report['details']['validation_checks'] = validation_checks\n",
    "            \n",
    "            # Statistiques\n",
    "            print(f\"\\n STATISTIQUES:\")\n",
    "            print(f\"   Nœuds: {num_nodes:,}\")\n",
    "            print(f\"   Arêtes: {num_edges:,}\")\n",
    "            print(f\"   Feature dimension: {x.size(1)}\")\n",
    "            print(f\"   Degré moyen: {num_edges * 2 / num_nodes:.2f}\")\n",
    "            print(f\"   Device: {x.device}\")\n",
    "            print(f\"   Sparsité x: {torch.mean((x == 0).float()):.3f}\")\n",
    "            print(f\"   Sparsité edge_attr: {torch.mean((edge_attr == 0).float()):.3f}\")\n",
    "            \n",
    "            report['details']['stats'] = {\n",
    "                'num_nodes': num_nodes,\n",
    "                'num_edges': num_edges,\n",
    "                'feature_dim': x.size(1),\n",
    "                'avg_degree': num_edges * 2 / num_nodes,\n",
    "                'device': str(x.device),\n",
    "                'sparsity_x': float(torch.mean((x == 0).float())),\n",
    "                'sparsity_edge_attr': float(torch.mean((edge_attr == 0).float()))\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            print(\" Tenseurs requis manquants pour GNN\")\n",
    "    else:\n",
    "        print(f\" Structure non-dict: {type(data)}\")\n",
    "        report['errors'].append(f\"Structure non-dict: {type(data)}\")\n",
    "    \n",
    "    # Conclusion\n",
    "    print(f\"\\n CONCLUSION:\")\n",
    "    if report['gnn_ready']:\n",
    "        print(\"    PRÊT POUR GNN !\")\n",
    "    elif report['contains_pytorch']:\n",
    "        print(\"     Contient PyTorch mais problèmes détectés\")\n",
    "    else:\n",
    "        print(\"    PAS un objet PyTorch valide\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# %% [markdown]\n",
    "##  Vérification des Fichiers avec Structure Correcte\n",
    "\n",
    "# %%\n",
    "# Chemins des fichiers à vérifier\n",
    "files_to_check = [\n",
    "     \"../data/05_model_input/gnn_pytorch_data.pkl\",\n",
    "    \"../data/05_model_input/baseline_gnn_pytorch_data.pkl\"\n",
    "]\n",
    "\n",
    "# Vérifier chaque fichier\n",
    "reports = []\n",
    "for file_path in files_to_check:\n",
    "    report = verify_pytorch_object_corrected(file_path)\n",
    "    reports.append(report)\n",
    "\n",
    "# %% [markdown]\n",
    "##  Résumé Final\n",
    "\n",
    "# %%\n",
    "def final_summary_corrected(reports):\n",
    "    \"\"\"Résumé final de toutes les vérifications\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" RÉSUMÉ FINAL - VERSION CORRIGÉE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    ready_for_gnn = []\n",
    "    issues_found = []\n",
    "    \n",
    "    for report in reports:\n",
    "        file_name = report['file_name']\n",
    "        \n",
    "        if report['gnn_ready']:\n",
    "            ready_for_gnn.append(file_name)\n",
    "            print(f\" {file_name}: PRÊT POUR GNN\")\n",
    "        else:\n",
    "            issues_found.append(file_name)\n",
    "            print(f\" {file_name}: PROBLÈMES DÉTECTÉS\")\n",
    "            for error in report['errors'][:3]:  # Limiter à 3 erreurs\n",
    "                print(f\"   • {error}\")\n",
    "    \n",
    "    print(f\"\\n BILAN:\")\n",
    "    print(f\"   Fichiers prêts GNN: {len(ready_for_gnn)}/{len(reports)}\")\n",
    "    \n",
    "    if len(ready_for_gnn) == len(reports):\n",
    "        print(\"    TOUS LES FICHIERS SONT PRÊTS POUR L'ENTRAÎNEMENT GNN !\")\n",
    "        print(\"\\n PROCHAINE ÉTAPE:\")\n",
    "        print(\"   Vous pouvez maintenant entraîner votre GNN avec ces données !\")\n",
    "        print(\"   Format d'utilisation:\")\n",
    "        print(\"   ```python\")\n",
    "        print(\"   import pickle\")\n",
    "        print(\"   with open('data/05_model_input/gnn_pytorch_data.pkl', 'rb') as f:\")\n",
    "        print(\"       data = pickle.load(f)\")\n",
    "        print(\"   x, edge_index, edge_attr = data['x'], data['edge_index'], data['edge_attr']\")\n",
    "        print(\"   ```\")\n",
    "    elif len(ready_for_gnn) > 0:\n",
    "        print(f\"     Seuls {ready_for_gnn} sont prêts\")\n",
    "    else:\n",
    "        print(\"    AUCUN FICHIER N'EST PRÊT POUR GNN\")\n",
    "\n",
    "final_summary_corrected(reports)\n",
    "\n",
    "# %% [markdown]\n",
    "##  Test de Chargement Direct pour GNN\n",
    "\n",
    "# %%\n",
    "def test_direct_gnn_loading(file_path):\n",
    "    \"\"\"Test direct de chargement des tenseurs pour GNN\"\"\"\n",
    "    try:\n",
    "        print(f\"\\n TEST DIRECT: {Path(file_path).name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Chargement direct\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Extraction des tenseurs\n",
    "        x = data['x']\n",
    "        edge_index = data['edge_index']\n",
    "        edge_attr = data['edge_attr']\n",
    "        \n",
    "        print(f\" Chargement réussi\")\n",
    "        print(f\"   x (node features): {x.shape} {x.dtype}\")\n",
    "        print(f\"   edge_index (connections): {edge_index.shape} {edge_index.dtype}\")\n",
    "        print(f\"   edge_attr (edge features): {edge_attr.shape} {edge_attr.dtype}\")\n",
    "        \n",
    "        # Test d'une opération GNN basique\n",
    "        print(f\"\\n Test opération GNN basique:\")\n",
    "        \n",
    "        # Test 1: Moyenne des features de nœuds\n",
    "        node_mean = torch.mean(x, dim=0)\n",
    "        print(f\"    Moyenne node features: {node_mean.shape}\")\n",
    "        \n",
    "        # Test 2: Indexing avec edge_index\n",
    "        source_nodes = x[edge_index[0]]  # Features des nœuds source\n",
    "        target_nodes = x[edge_index[1]]  # Features des nœuds target\n",
    "        print(f\"    Indexing source/target: {source_nodes.shape}, {target_nodes.shape}\")\n",
    "        \n",
    "        # Test 3: Message passing simple (moyenne voisins)\n",
    "        try:\n",
    "            # Créer un message simple (somme source + target + edge)\n",
    "            messages = source_nodes + target_nodes + edge_attr\n",
    "            print(f\"    Message passing basique: {messages.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"     Message passing échoué: {e}\")\n",
    "        \n",
    "        print(f\"    {Path(file_path).name} est COMPATIBLE avec les opérations GNN !\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur test direct: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test sur les deux fichiers\n",
    "for file_path in files_to_check:\n",
    "    if Path(file_path).exists():\n",
    "        test_direct_gnn_loading(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9620d624-5391-45c0-9787-1e5ce60ad11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['x', 'edge_index', 'edge_attr', 'num_nodes', 'num_edges'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/05_model_input/baseline_gnn_pytorch_data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(type(data))\n",
    "print(data.keys() if isinstance(data, dict) else data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46668b-c2d9-4405-8c3f-e3369ba2ec1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
